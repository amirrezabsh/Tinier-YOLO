{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "END-XpLwDg-N"
      },
      "outputs": [],
      "source": [
        "# %pip install -r requirements.txt\n",
        "# %rm -r ./datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "emygoNChCUGt"
      },
      "outputs": [],
      "source": [
        "from model import TinierYolo, train_step, eval_step, YoloLoss\n",
        "from dataset_loader import DatasetLoader\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbr8MNukErnH",
        "outputId": "0296c51f-45bd-402a-9d15-42a21efc8315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load completed: voc/2007\n",
            "tfds.core.DatasetInfo(\n",
            "    name='voc',\n",
            "    full_name='voc/2007/4.0.0',\n",
            "    description=\"\"\"\n",
            "    This dataset contains the data from the PASCAL Visual Object Classes Challenge,\n",
            "    corresponding to the Classification and Detection competitions.\n",
            "    \n",
            "    In the Classification competition, the goal is to predict the set of labels\n",
            "    contained in the image, while in the Detection competition the goal is to\n",
            "    predict the bounding box and label of each individual object.\n",
            "    WARNING: As per the official dataset, the test set of VOC2012 does not contain\n",
            "    annotations.\n",
            "    \"\"\",\n",
            "    config_description=\"\"\"\n",
            "    This dataset contains the data from the PASCAL Visual Object Classes Challenge\n",
            "    2007, a.k.a. VOC2007.\n",
            "    \n",
            "    A total of 9963 images are included in this dataset, where each image\n",
            "    contains a set of objects, out of 20 different classes, making a total of\n",
            "    24640 annotated objects.\n",
            "    \n",
            "    \"\"\",\n",
            "    homepage='http://host.robots.ox.ac.uk/pascal/VOC/voc2007/',\n",
            "    data_dir='datasets/voc/2007/4.0.0',\n",
            "    file_format=tfrecord,\n",
            "    download_size=868.85 MiB,\n",
            "    dataset_size=837.73 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
            "        'image/filename': Text(shape=(), dtype=string),\n",
            "        'labels': Sequence(ClassLabel(shape=(), dtype=int64, num_classes=20)),\n",
            "        'labels_no_difficult': Sequence(ClassLabel(shape=(), dtype=int64, num_classes=20)),\n",
            "        'objects': Sequence({\n",
            "            'bbox': BBoxFeature(shape=(4,), dtype=float32),\n",
            "            'is_difficult': bool,\n",
            "            'is_truncated': bool,\n",
            "            'label': ClassLabel(shape=(), dtype=int64, num_classes=20),\n",
            "            'pose': ClassLabel(shape=(), dtype=int64, num_classes=5),\n",
            "        }),\n",
            "    }),\n",
            "    supervised_keys=None,\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'test': <SplitInfo num_examples=4952, num_shards=4>,\n",
            "        'train': <SplitInfo num_examples=2501, num_shards=2>,\n",
            "        'validation': <SplitInfo num_examples=2510, num_shards=2>,\n",
            "    },\n",
            "    citation=\"\"\"@misc{pascal-voc-2007,\n",
            "    \tauthor = \"Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.\",\n",
            "    \ttitle = \"The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2007 {(VOC2007)} {R}esults\",\n",
            "    \thowpublished = \"http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html\"}\"\"\",\n",
            ")\n",
            "Train dataset sample:\n",
            "Images: (16, 416, 416, 3)\n",
            "BBoxes: (16, 100, 4)\n",
            "Labels: (16, 100)\n",
            "Test dataset sample:\n",
            "Images: (16, 416, 416, 3)\n",
            "BBoxes: (16, 100, 4)\n",
            "Labels: (16, 100)\n",
            "Validation dataset sample:\n",
            "Images: (16, 416, 416, 3)\n",
            "BBoxes: (16, 100, 4)\n",
            "Labels: (16, 100)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pascal_voc_2007 = 'voc/2007'\n",
        "pascal_voc_2012 = 'voc/2012'\n",
        "\n",
        "# Instantiate DatasetLoader\n",
        "loader = DatasetLoader(pascal_voc_2007)\n",
        "\n",
        "# Get train, test, and validation datasets\n",
        "train_dataset = loader.get_dataset(split=0)\n",
        "test_dataset = loader.get_dataset(split=1)\n",
        "validation_dataset = loader.get_dataset(split=2)\n",
        "\n",
        "# Print dataset structures\n",
        "for images, bboxes, labels in train_dataset.take(1):\n",
        "    print(\"Train dataset sample:\")\n",
        "    print(\"Images:\", images.shape)\n",
        "    print(\"BBoxes:\", bboxes.shape)\n",
        "    print(\"Labels:\", labels.shape)\n",
        "\n",
        "for images, bboxes, labels in test_dataset.take(1):\n",
        "    print(\"Test dataset sample:\")\n",
        "    print(\"Images:\", images.shape)\n",
        "    print(\"BBoxes:\", bboxes.shape)\n",
        "    print(\"Labels:\", labels.shape)\n",
        "\n",
        "for images, bboxes, labels in validation_dataset.take(1):\n",
        "    print(\"Validation dataset sample:\")\n",
        "    print(\"Images:\", images.shape)\n",
        "    print(\"BBoxes:\", bboxes.shape)\n",
        "    print(\"Labels:\", labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "id": "-m49jPGzExcA",
        "outputId": "15bfcdbd-a263-4994-8bc2-b26c1453655c"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "tinier_yolo = TinierYolo(num_classes=80).model\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "yolo_loss = YoloLoss()\n",
        "\n",
        "# # Instantiate the custom train and eval steps\n",
        "# train_step = CustomTrainStep(model=tinier_yolo.model, loss_fn=yolo_loss, optimizer=optimizer)\n",
        "# eval_step = CustomEvalStep(model=tinier_yolo.model)\n",
        "\n",
        "# usage\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    for batch_images, batch_boxes, batch_labels in train_dataset:\n",
        "\n",
        "        loss = train_step(tinier_yolo, batch_images, (batch_labels, batch_boxes), optimizer, yolo_loss)\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {loss}\")\n",
        "\n",
        "# Evaluate on test dataset after each epoch\n",
        "for batch_images, batch_labels in test_dataset:\n",
        "    predictions = eval_step(batch_images)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
